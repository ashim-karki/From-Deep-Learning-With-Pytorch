{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2407cebc7f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "datapath = '..\\C7'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    datapath, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    datapath, train=False, download=False, # train = False then val_set is downloaded\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "softmax = nn.Softmax(dim=1) # along rows\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                 [1.0, 2.0, 3.0]])\n",
    "softmax(x)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0900, 0.2447, 0.6652]), tensor(1.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding softmax\n",
    "\n",
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "softmax(x), softmax(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 2 # number of output classes i.e birds or airplane\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear( # first input layer\n",
    "        3072, # 3x32x32 = 3072\n",
    "        512, # hidden layer\n",
    "    ),\n",
    "    nn.Tanh(), # activation function\n",
    "    nn.Linear(\n",
    "        512, # hidden layer\n",
    "        n_out, # output layer\n",
    "    ),\n",
    "    nn.LogSoftmax(dim=1) # as nn.NLLloss is used. logsoftmax is used instead of softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing up, our loss for classification can be computed as follows. For each sample in the batch:\n",
    "- Run the forward pass, and obtain the output values from the last (linear) layer.\n",
    "- Compute their softmax, and obtain probabilities.\n",
    "- Take the predicted probability corresponding to the correct class (the likelihood of the parameters). Note that we know what the correct class is because it’s a supervised problem—it’s our ground truth.\n",
    "- Compute its logarithm, slap a minus sign in front of it, and add it to the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 7.046943\n",
      "Epoch: 1, Loss: 1.872851\n",
      "Epoch: 2, Loss: 5.895400\n",
      "Epoch: 3, Loss: 2.943361\n",
      "Epoch: 4, Loss: 11.279670\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "\n",
    "# not training in batches will take too much time and evaluation of each loss that backpropagates is not appropriate\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Printing the loss of only the last image\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.374087\n",
      "Epoch: 1, Loss: 0.678669\n",
      "Epoch: 2, Loss: 0.642162\n",
      "Epoch: 3, Loss: 0.531003\n",
      "Epoch: 4, Loss: 0.480707\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader: # imgs is a tensor of size (64 x 3 x 32 x32), labels a tensor of size\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1)) # 64 x 3072\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss))) # prints loss of random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.NLLLoss() + nn.LogSoftmax() = nn.CrossEntropyLoss()\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.307775\n",
      "Epoch: 1, Loss: 0.831813\n",
      "Epoch: 2, Loss: 0.436497\n",
      "Epoch: 3, Loss: 0.459527\n",
      "Epoch: 4, Loss: 0.267532\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the number of parameters\n",
    "\n",
    "numel_list = [p.numel()\n",
    "                for p in model.parameters()\n",
    "                if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "- Input features = 3072 (1 neuron for each feature)\n",
    "- Output features = 1024 (1 for each neuron in 2nd layer)\n",
    "- For fully connected layer = each neuron connected to successive layer = 3072 x 1024 = 3145728\n",
    "- Adding bias after multiplication on each output neuron = 1024 \n",
    "\n",
    "2.\n",
    "- weights = 1024 x 512 = 524288\n",
    "- bias = 512\n",
    "\n",
    "3.\n",
    "- weight = 512 x 128 = 65536\n",
    "- bias = 128\n",
    "\n",
    "4.\n",
    "- weight = 128 x 2 = 512\n",
    "- bias = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is very large for even a small image that's why CNN is used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
