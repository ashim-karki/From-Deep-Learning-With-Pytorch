{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hereâ€™s a list of the\n",
    "possible values for the dtype argument:\n",
    "- torch.float32 or torch.float: 32-bit floating-point\n",
    "- torch.float64 or torch.double: 64-bit, double-precision floating-point\n",
    "- torch.float16 or torch.half: 16-bit, half-precision floating-point\n",
    "- torch.int8: signed 8-bit integers\n",
    "- torch.uint8: unsigned 8-bit integers\n",
    "- torch.int16 or torch.short: signed 16-bit integers\n",
    "- torch.int32 or torch.int: signed 32-bit integers\n",
    "- torch.int64 or torch.long: signed 64-bit integers\n",
    "- torch.bool: Boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default data type for tensors is 32-bit floating-point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Higher precision, like 64-bit, will not buy improvements in the accuracy of a model and will require more memory and\n",
    "computing time. \n",
    "- The 16-bit floating-point, half-precision data type is not present natively in standard CPUs, but it is offered on modern GPUs. It is possible to switch to half-precision to decrease the footprint of a neural network model if needed, with a\n",
    "minor impact on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "bit64tensor = torch.tensor([2, 2]) # creates a 64-bit int tensor as a indexing tensor\n",
    "bit32tensor = torch.tensor([2.0, 2.0]) # creates a 32-bit float tensor\n",
    "print(bit64tensor.dtype)\n",
    "print(bit32tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "double_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# casting\n",
    "double_points = torch.zeros(10, 2).short()\n",
    "double_points.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When mixing input types in operations, the inputs are converted to the larger type automatically. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
